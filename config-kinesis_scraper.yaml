###################################
## Section: Basic Configuration ##
###################################

# ----------------------
# Property: debug_level
# ----------------------
# Description: The debug output level. INFO is the default and provides general status logging
# Possible values: DEBUG|INFO|WARNING|ERROR
#
debug_level: DEBUG

# ----------------------
# Property: region_name
# ----------------------
# Description: The AWS region
#
region_name: us-east-1

# ----------------------
# Property: stream_name
# ----------------------
# Description: The name of the stream you want to scrape
# Example value: user-activities
#
stream_name: user-activities-new

# -------------------
# Property: shardIds
# -------------------
# Description: An array of shard ids to scrape. If a blank array is passed or the property is commented out,
# all shards will be scraped
#
# Example value for all shards:  (or just comment out the property entirely)
# shardIds: []
#
# Example value for a list of only specific shards to scrape:
# shardIds:
#  - shardId-000000000000
#  - shardId-000000000001
#
#shard_ids: ['shardId-000000000005']
#shard_ids: []
shard_ids: ['shardId-000000000000']

###################################
## Section: Stream Scrape Range  ##
###################################

# ---------------------------
# Property: starting_position
# ---------------------------
# Description: At which point in the stream should the scraper begin reading from? This value is used directly
# as the ShardIteratorType= value in the boto3 get_shard_iterator() call
#
# Possible values: AT_SEQUENCE_NUMBER
#                  AFTER_SEQUENCE_NUMBER
#                  TRIM_HORIZON
#                  LATEST
#                  AT_TIMESTAMP
#
# Note: TRIM_HORIZON = Start with the oldest record in the stream
#
# Note2: If set to AT_SEQUENCE_NUMBER or AFTER_SEQUENCE_NUMBER, "shardIds" must be populated with a single shard id
# as sequence ids are unique per-shard
#
#starting_position: "AT_SEQUENCE_NUMBER"
starting_position: AT_SEQUENCE_NUMBER

# ---------------------------
# Property: timestamp
# ---------------------------
# Description: Only used if starting_position = AT_TIMESTAMP
# Format (UTC): YYYY-MM-DD HH:MM:SS
#
starting_timestamp: "2022-12-01 00:00:00"

# ---------------------------
# Property: sequence_number
# ---------------------------
# Description: Only used if starting_position = AT_SEQUENCE_NUMBER or AFTER_SEQUENCE_NUMBER
#
starting_sequence_number: 49643934656360832602610280800286668503574119240605630466

# ---------------------------
# Property: ending_position
# ---------------------------
# Description: At which point the scraper should stop reading from the stream.
# Possible values:  TOTAL_RECORDS_PER_SHARD
#                   AT_SEQUENCE_NUMBER
#                   AFTER_SEQUENCE_NUMBER
#                   BEFORE_SEQUENCE_NUMBER
#                   AT_TIMESTAMP
#                   BEFORE_TIMESTAMP
#                   AFTER_TIMESTAMP
#                   LATEST
#
# Note: AT_SEQUENCE_NUMBER = Read upto and including the specified sequence number
# Note: AFTER_SEQUENCE_NUMBER = Read upto and including the specified sequence number as well as the very next message
# Note: BEFORE_SEQUENCE_NUMBER = Read upto and including the message directly preceding the specified sequence number
#
# *_SEQUENCE_NUMBER Note: If set to one of the *_SEQUENCE_NUMBER values, "shardIds" must be populated with a
#                         single shard id as sequence ids are unique per-shard
#
# Note: AT_TIMESTAMP = Read upto and including the first occurrence of a single, or set of contiguous messages,
#       where ApproximateArrivalTimestamp matches the specified timestamp
# Note: AFTER_TIMESTAMP = Read upto and including the next single, or set of continuous messages, where
#       ApproximateArrivalTimestamp is later by any amount of time, than the specified timestamp
# Note: BEFORE_TIMESTAMP = Read upto and including the messages directly preceding the first message in the stream
#       that has ApproximateArrivalTimestamp equal to the specified timestamp
#
# TIMESTAMP Note: Due to the ApproximateArrivalTimestamp being approximate, it is possible some messages may exist
#           after the intended stopping point in the stream that have an earlier timestamp than the specified stopping
#           point. Aws makes this unavoidable due to using approximate timestamps. If precision is needed, consider
#           using TOTAL_RECORDS or one of the *_SEQUENCE_NUMBER options
#
# LATEST Note: If set to LATEST, the Kinesis SLR will continue to read the stream until the
#              max_empty_polls limit is reached
#
#
ending_position: AT_TIMESTAMP

# ---------------------------
# Property: timestamp
# ---------------------------
# Description: Only used if ending_position = *_TIMESTAMP
# Format (UTC): YYYY-MM-DD HH:MM:SS
#
ending_timestamp: "2022-12-01 00:00:00"

# --------------------------------
# Property: ending_sequence_number
# --------------------------------
# Description: Only used if ending_sequence_number = *_SEQUENCE_NUMBER
#
ending_sequence_number: 49634793967732681113891714384157638505909056619063279650

# ----------------------------------------------
# Property: ending_total_records_per_shard_value
# ----------------------------------------------
# Description: Only used if ending_position = TOTAL_RECORDS_PER_SHARD
#
#
total_records_per_shard: 10000

#####################################
## Stream Processing Configuration ##
#####################################

# -------------------------
# Property: poll_batch_size
# -------------------------
# Description: The number of records fetched per poll (used via boto3.kinesis.get_records(Limit=X))
#
# AWS Quota Note: The next two values must be considered carefully from an engineering perspective
# as AWS enforces the following quota on reads from shards:
# https://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html
#   - GetRecords can retrieve up to 10 MB of data per call from a single shard,
#     and up to 10,000 records per call.
#   - Each call to GetRecords is counted as one read transaction.
#   - Each shard can support up to five read transactions per second.
#   - Each read transaction can provide up to 10,000 records with an upper quota of 10 MB per transaction.
# Therefore, if you have 1MB messages, this value cannot be greater than 10
#
poll_batch_size: 100 # Max 500

# --------------------
# Property: poll_delay
# --------------------
# Description: The wait delay between each GetRecords poll call.
#
# Note: All calls are handled in a liner fashion, no parallelism/multi-threading is used. If it takes 1 second for
# each boto3 API call to complete, that will result in a throughput of 1 call-per-second. This parameter simply adds a
# time.sleep(poll_delay) call in-between each boto3 get_records() call with the value specified in poll_delay.
# set debug_level above to DEBUG to see the elapsed time for each get_records() call
#
# AWS Quota Note: This value must be considered carefully from an engineering perspective and engineers
# must take into account the total number of consumers making polls to a shard, as well as the
# poll_batch_size config option, as well as the average boto3 get_records() API call duration, to ensure not to
# exceed a total aggregate of 5 reads/second or 2MB/second per shard, otherwise any pollers for the next 5 seconds
# will receive a ProvisionedThroughputExceededException
#
poll_delay: "0.0"

# --------------------------------
# Property: max_empty_polls
# --------------------------------
# Description: Kinesis will often return a blank set of records on a poll depending on how much time has
# elapsed in the stream between messages being published and how sparsely the stream is populated.
# It is generally recommended to attempt to repeat subsequent polls if the record set is empty a
# variable number of times depending on how the stream is used.
#
# Some examples and research: https://stackoverflow.com/a/66492331
# Also see for more info: https://medium.com/software-ascending/surprises-from-polling-kinesis-a76462a7efd4
# "A Kinesis shard is time-sliced into possibly-empty buckets, and each call to GetRecords
#  will only return records from a single bucket."
#
# It is important to note, that relying on "MillisBehindLatest" has proven to be unreliable.
#
# Once the number of contiguous polls that returned empty records matches the max_empty_polls value, the
# Kinesis-SLR will consider the shard to be fully read and stop scraping messages. A rule of thumb is
# 2 empty polls per every 500 contiguous seconds of "empty time" that could exist between messages anywhere
# in the stream from the oldest message until now. From my testing, a 24 hour gap between messages resulted
# in upto 104 empty polls
#
max_empty_polls: 250 # Max 5000
